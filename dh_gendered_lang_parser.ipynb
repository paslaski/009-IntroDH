{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dh_gendered_lang_parser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNz56mcJNC4+6huOGfDUIOB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paslaski/009-IntroDH/blob/main/dh_gendered_lang_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCrF55lJcoSd",
        "outputId": "3e29f617-2e2a-4674-a1f2-eccdd664ed40"
      },
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "from nltk import Tree\n",
        "from collections import Counter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (56.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiQFuwlqeb97"
      },
      "source": [
        "en_nlp = spacy.load('en')\n",
        "\n",
        "doc = en_nlp(\"The quick brown fox jumps over the lazy dog.\")\n",
        "\n",
        "def to_nltk_tree(node):\n",
        "    if node.n_lefts + node.n_rights > 0:\n",
        "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
        "    else:\n",
        "        return node.orth_\n",
        "\n",
        "\n",
        "my_tree = [to_nltk_tree(sent.root) for sent in doc.sents]\n",
        "# my_tree = [to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD0NZHGxeeUk",
        "outputId": "d14be27c-d7b6-49ea-d4ce-9ae96f4ebbe2"
      },
      "source": [
        "[x.pretty_print() for x in my_tree]\n",
        "my_tree"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                jumps                  \n",
            "  ________________|____________         \n",
            " |    |     |     |    |      over     \n",
            " |    |     |     |    |       |        \n",
            " |    |     |     |    |      dog      \n",
            " |    |     |     |    |    ___|____    \n",
            "The quick brown  fox   .  the      lazy\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tree('jumps', ['The', 'quick', 'brown', 'fox', Tree('over', [Tree('dog', ['the', 'lazy'])]), '.'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo-1KiBhfNhC",
        "outputId": "98142d85-2d1b-4345-f3e9-4892a831810f"
      },
      "source": [
        "from __future__ import unicode_literals, print_function\n",
        "from spacy.lang.en import English # updated\n",
        "\n",
        "# from spacy.pipeline.tagger import DEFAULT_TAGGER_MODEL\n",
        "# from spacy.pipeline.dep_parser import DEFAULT_PARSER_MODEL\n",
        "\n",
        "raw_text = 'The fast woman jumped over the hoop. Hello, world. Here are two sentences.'\n",
        "# subtree (includes self): [The, fast, woman]\n",
        "# ancestors: [jumped]\n",
        "\n",
        "raw_text = 'The fast woman is a doctor. They saw me last Saturday. Hello, world. Here are two sentences.'\n",
        "# subtree (includes self): [The, fast, woman]\n",
        "# ancestors: [is]\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# nlp = English()\n",
        "\n",
        "# nlp.add_pipe(nlp.create_pipe('parser')) # updated\n",
        "# nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "\n",
        "# tagger_config = {\"model\": DEFAULT_TAGGER_MODEL}\n",
        "# nlp.add_pipe(\"tagger\", config=tagger_config)\n",
        "\n",
        "# parser_config = {\n",
        "#    \"moves\": None,\n",
        "#    \"update_with_oracle_cut_size\": 100,\n",
        "#    \"learn_tokens\": False,\n",
        "#    \"min_action_freq\": 30,\n",
        "#    \"model\": DEFAULT_PARSER_MODEL,\n",
        "# }\n",
        "# nlp.add_pipe(\"parser\", config=parser_config)\n",
        "\n",
        "# sentences = [sent.string.strip() for sent in doc.sents]\n",
        "# sentences\n",
        "\n",
        "doc = nlp(raw_text)\n",
        "for token in doc:\n",
        "    print(token.text, token.tag_, token.head.text, token.dep_)\n",
        "\n",
        "she_token = doc[2]\n",
        "ancestors = [x for x in she_token.ancestors]\n",
        "print(ancestors)\n",
        "[x for x in ancestors[0].subtree]\n",
        "# subtree (includes self): [The, fast, woman]\n",
        "# ancestors: [is]\n",
        "\n",
        "# they_token = doc[7]\n",
        "# [x for x in they_token.ancestors]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The DT woman det\n",
            "fast JJ woman amod\n",
            "woman NN is nsubj\n",
            "is VBZ is ROOT\n",
            "a DT doctor det\n",
            "doctor NN is attr\n",
            ". . is punct\n",
            "They PRP saw nsubj\n",
            "saw VBD saw ROOT\n",
            "me PRP saw dobj\n",
            "last JJ Saturday amod\n",
            "Saturday NNP saw npadvmod\n",
            ". . saw punct\n",
            "Hello UH Hello ROOT\n",
            ", , Hello punct\n",
            "world NN Hello npadvmod\n",
            ". . Hello punct\n",
            "Here RB are advmod\n",
            "are VBP are ROOT\n",
            "two CD sentences nummod\n",
            "sentences NNS are nsubj\n",
            ". . are punct\n",
            "[is]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[The, fast, woman, is, a, doctor, .]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYXfYdC2NWiv"
      },
      "source": [
        "fem_words = set([\"her\", \"hers\", \"herself\", \"she\", \"woman\", \"women\", \"mother\", \"mothers\", \"mom\", \"moms\", \"sister\", \"sisters\", \"wife\", \"wives\", \"aunt\", \"aunts\", \"womanly\", \"goddess\", \"goddesses\", \"girl\", \"girls\", \"queen\", \"queens\"])\n",
        "\n",
        "gn_words = set([\"their\", \"zir\", \"theirs\", \"zirs\", \"themself\", \"theirself\", \"they\", \"ze\", \"people\", \"persons\", \"person\", \"parent\", \"parents\", \"spouse\"])\n",
        "\n",
        "masc_words = set([\"he\", \"his\", \"hisself\", \"he\", \"man\", \"men\", \"father\", \"fathers\", \"dad\", \"dads\", \"brother\", \"brothers\", \"husband\", \"husbands\", \"uncle\", \"uncles\", \"manly\", \"god\", \"gods\", \"boy\", \"boys\", \"boi\", \"bruh\", \"king\", \"kings\"])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNYgqejvxAcs"
      },
      "source": [
        "def extract_gendered_deps(sentence, nlp, fem_words, gn_words, masc_words):\n",
        "# accepts: \n",
        "    # sentence: a single sentence to parse\n",
        "    # nlp: a spacy model for dependency parsing\n",
        "    # fem_words, gn_words, masc_words, dictionaries containing gendered words\n",
        "# returns:\n",
        "    # tuple of Counter objects: (fem, gn, masc)\n",
        "    # each contains unique adjectives, nouns, aux, verbs related to feminine-gendered, \n",
        "    # masculine-gendered, non-gendered words/pronouns defined by input dictionaries\n",
        "\n",
        "    # intialize Counter objects to return\n",
        "    fem, gn, masc = Counter(), Counter(), Counter()\n",
        "\n",
        "    # use spacy to perform dependency parsing\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    for token in doc: # iterate through all tokens in sentence\n",
        "        # check each word against gendered language dictionaries \n",
        "        if token.text.lower() in fem_words:\n",
        "            extract_ancestors(token, fem)\n",
        "        elif token.text.lower() in gn_words:\n",
        "            extract_ancestors(token, gn)\n",
        "        elif token.text.lower() in masc_words:\n",
        "            extract_ancestors(token, masc)\n",
        "\n",
        "    return (fem, gn, masc)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJZC4HREKmWl"
      },
      "source": [
        "def extract_ancestors(token, ancestor_ctr):\n",
        "# accepts:\n",
        "#         token: spacy token, contains references to ancestors\n",
        "#         ancestor_ctr: Counter() object, hashmap of counts of word occurences\n",
        "# returns:\n",
        "#         ancestor_ctr: list of adjectives, nouns, verbs, auxiliary words related to token\n",
        "\n",
        "\n",
        "    ## TODO: double check we get all possible associated words (expand ancestors prolly ok?)\n",
        "\n",
        "    ancestors = set()\n",
        "\n",
        "    accepted_pos_types = {'ADJ': 1, 'NOUN': 1, 'VERB': 1, 'AUX': 1}\n",
        "\n",
        "    # iterate over ancestors\n",
        "    for word in token.ancestors:\n",
        "        if word.pos_ in accepted_pos_types:\n",
        "            ancestors.add(word.text.lower())\n",
        "\n",
        "        # will we need some sorta fancy recursive solution, cycles?\n",
        "        for deeper_word in word.subtree:\n",
        "            if deeper_word.pos_ in accepted_pos_types:\n",
        "                ancestors.add(deeper_word.text.lower())\n",
        "          \n",
        "    # iterate over subtree\n",
        "    for word in token.subtree:\n",
        "        if word.pos_ in accepted_pos_types:\n",
        "            ancestors.add(word.text.lower())\n",
        "\n",
        "    # for each unique word (set) increment counter object once\n",
        "    for accepted_word in ancestors:\n",
        "        ancestor_ctr[accepted_word] += 1\n",
        "\n",
        "    return ancestor_ctr"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qe-bMHuPVTL",
        "outputId": "fc56131e-2c06-4f4a-b72f-95855efcf4a3"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "raw_text = 'The fast woman jumped over the hoop. You go girl! Hello, world. Here are two sentences. He swang the bat. Are they on your team?'\n",
        "\n",
        "fem, gn, masc = extract_gendered_deps(raw_text, nlp, fem_words, gn_words, masc_words)\n",
        "fem, gn, masc"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Counter({'fast': 1, 'girl': 1, 'go': 1, 'hoop': 1, 'jumped': 1, 'woman': 1}),\n",
              " Counter({'are': 1, 'team': 1}),\n",
              " Counter({'bat': 1, 'swang': 1}))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXD-lADF5dd_",
        "outputId": "0b21acdb-4c15-401a-fef0-2fa39e5dc2b5"
      },
      "source": [
        "def append_list_for_me(sentence, input_list):\n",
        "    words = [x for x in sentence.split(' ')]\n",
        "    for word in words:\n",
        "        input_list.append(word)\n",
        "\n",
        "    return input_list\n",
        "\n",
        "sentence = 'the quick brown fox jumped over the lazy dog'\n",
        "input_list = []\n",
        "\n",
        "append_list_for_me(sentence, input_list)\n",
        "append_list_for_me(sentence, input_list)\n",
        "append_list_for_me(sentence, input_list)\n",
        "input_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'quick',\n",
              " 'brown',\n",
              " 'fox',\n",
              " 'jumped',\n",
              " 'over',\n",
              " 'the',\n",
              " 'lazy',\n",
              " 'dog',\n",
              " 'the',\n",
              " 'quick',\n",
              " 'brown',\n",
              " 'fox',\n",
              " 'jumped',\n",
              " 'over',\n",
              " 'the',\n",
              " 'lazy',\n",
              " 'dog',\n",
              " 'the',\n",
              " 'quick',\n",
              " 'brown',\n",
              " 'fox',\n",
              " 'jumped',\n",
              " 'over',\n",
              " 'the',\n",
              " 'lazy',\n",
              " 'dog']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    }
  ]
}